# Quantum vs. Classical Kernel Approximation Experiments

This project provides a robust framework for systematically comparing the performance of classical Support Vector Machines (SVMs) with Radial Basis Function (RBF) kernels against various Quantum Support Vector Classifiers (QSVCs).

The primary research goals are:
1.  **Quantum Learning RBF Boundaries**: To assess how effectively different quantum kernels (both fixed and trainable) can learn decision boundaries generated by a classical RBF kernel.
2.  **RBF Learning Quantum Boundaries**: To test the reverse: how well a classical RBF SVM can approximate a decision boundary that is natively separable by a specific quantum kernel.

The framework is designed for reproducibility, parallel execution, and easy extension.

## Framework Architecture

The workflow is divided into three distinct, stateless stages to ensure scientific rigor and scalability:

1.  **Job Launcher (`main.py`)**: The main entry point. It reads a master configuration file and schedules all the individual experimental trials to be run in parallel across multiple CPU cores.
2.  **Trial Worker (`experiment_worker.py`)**: The core execution engine. Each worker runs a *single, self-contained trial* with a specific configuration and a unique random seed. It handles data generation, model training for a specific data size, and evaluation, saving the raw results to a unique file.
3.  **Result Aggregator (`aggregate_results.py`)**: After all trials are complete, this script reads the immutable raw result files for an experiment, computes statistics (mean and standard deviation) across all trials, and generates the final, publication-quality plots.

This separation ensures that trials are perfectly reproducible and that the analysis is decoupled from the raw data generation.

## Directory Structure

```
/ApproximationExperiments/
|-- configs/                # Master JSON files defining experiment batches.
|-- src/                    # All source code.
|   |-- main.py             # Master script to launch all experiments.
|   |-- experiment_worker.py  # Executes a SINGLE trial.
|   |-- aggregate_results.py  # Reads trials, averages, and plots.
|   |-- lib/                  # Core library of shared functions.
|-- results/                # Raw output from individual trials (auto-generated).
|   |-- [experiment_name]/
|   |   |-- trial_seed_42.pkl # Each trial gets a unique, permanent file.
|-- plots/                  # Final, aggregated plots (auto-generated).
|   |-- [experiment_name].png
|-- README.md               # This file.
```

## How to Run an Experiment

Running an experiment is a simple three-step process.

### Step 1: Define the Experiment

All experiments are defined in `.json` files within the `configs/` directory. You can create a new file or edit an existing one like `sample_experiment.json`.

Key configuration options include:
-   `experiment_name`: A unique name that will be used for the results and plots directories.
-   `enabled`: Set to `true` to run the experiment, `false` to skip it.
-   `execution_params`: Defines how many times to run the experiment (`num_trials`) and the starting random seed (`base_seed`).
-   `experiment_type`: Can be `quantum_learns_rbf` or `rbf_learns_quantum`.
-   `rbf_data_params` / `data_generation_params`: Parameters for generating the respective datasets.
-   `qsvc_tuning_params`: Defines the hyperparameter space for the quantum kernel search.
-   `comparison_train_sizes`: A list of training data sizes to evaluate, which generates the learning curves.

### Step 2: Launch the Trials

From within the `src/` directory, run the main launcher script. You must point it to your configuration file and can specify the number of CPU cores to use.

```bash
# Example from within the src/ directory
python main.py --config ../configs/sample_experiment.json --workers 4
```

This will start processing all *enabled* experiments in your config file. The script is checkpointed at the trial level; if you stop and restart it, it will automatically skip any trials that have already been completed.

### Step 3: Aggregate and Plot the Results

Once the launcher finishes, run the aggregation script. You only need to provide the `experiment_name` that you wish to analyze.

```bash
# Example from within the src/ directory
python aggregate_results.py --exp "Quantum-Learns-RBF-Gamma1.5-Noise0"
```

This will read all the corresponding `.pkl` files from the `results/` directory, compute the mean and standard deviation for all metrics, and save a final plot with error bands to the `plots/` directory.
